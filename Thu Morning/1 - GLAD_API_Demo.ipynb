{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c23836bf-983b-4b9b-af47-ac1843b6d3e3",
   "metadata": {},
   "source": [
    "Copied from https://bitbucket.org/okusche/glad_api_demo/src/brightcon2022/\n",
    "\n",
    "**Conference Notebook Kernel: `bw25`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0d3335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6152a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLAD API base URL\n",
    "base_url = 'https://www.globallcadataaccess.org/api/v1/'\n",
    "\n",
    "# We need an API key to access the API which we obtain from our user account there\n",
    "api_key = '42ef8e1ad9e092071ce7004c1ca87574'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72787170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, we send some request to see whether everything works as it's supposed to\n",
    "try:\n",
    "    url = base_url + 'search?query=maize'\n",
    "    req_headers = {\n",
    "        'api-key': api_key\n",
    "    }\n",
    "    response = requests.get(url, headers = req_headers)\n",
    "    result = response.json()\n",
    "    print(\"total results: \", result['resultInfo']['totalCount'])\n",
    "    print(\"response body:\\n\", response.text)\n",
    "except:\n",
    "    print(\"Invalid URL or some error occured while making the request to the specified URL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aeda71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's filter for stuff that is\n",
    "#  - available online (publiclyAccessible=true)\n",
    "#  - available free of charge (free=true)\n",
    "#  - in ILCD format (format=ILCD)\n",
    "\n",
    "try:\n",
    "    url = base_url + 'search?free=true&publiclyAccessible=true&format=ILCD'\n",
    "    req_headers = {\n",
    "        'api-key': api_key\n",
    "    }\n",
    "    response = requests.get(url, headers = req_headers)\n",
    "    result = response.json()\n",
    "    print(\"total results: \", result['resultInfo']['totalCount'])\n",
    "    print(\"first result's process name:\\n\", result['data'][0]['name'])\n",
    "except:\n",
    "    print(\"Invalid URL or some error occured while making the request to the specified URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed46a67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's examine where the results come from\n",
    "aggregations = result['aggregations']\n",
    "\n",
    "\n",
    "def find_aggregation(data, aggregation_name):\n",
    "    return list(filter(lambda x: x['name'] == aggregation_name, data))\n",
    "\n",
    "\n",
    "def show_aggregation(aggregation_name):\n",
    "    agg = find_aggregation(aggregations, aggregation_name)\n",
    "    print(\"no. of results from \", aggregation_name)\n",
    "    print(\"-\" * (20 + len(aggregation_name)))      \n",
    "    for i in agg[0]['entries']:\n",
    "        print(i['key'], i['count'])\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "agg_dataproviders = find_aggregation(aggregations, 'dataprovider')\n",
    "print(\"data providers aggregation:\\n\", agg_dataproviders, \"\\n\")\n",
    "\n",
    "show_aggregation('dataprovider')\n",
    "\n",
    "show_aggregation('location')\n",
    "\n",
    "show_aggregation('supportedNomenclatures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027c9615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we convert the result into a dataframe\n",
    "df = pd.DataFrame.from_dict(pd.json_normalize(result['data']), orient='columns')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa56b941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's reorder it nicely\n",
    "df = pd.DataFrame(df, columns=['name', 'location', 'category', 'dataprovider', 'dataSetUrl', 'supportedNomenclatures', 'reviewType', 'reviewers', 'description'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c122e763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve a dataset in original XML format (the process dataset only)\n",
    "ds_url = df.at[0,'dataSetUrl']\n",
    "print(\"retrieving \" + ds_url)\n",
    "response = requests.get(ds_url)\n",
    "xml_dataset = response.text\n",
    "print(xml_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7de8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve a dataset in original XML format (ZIP file with dependencies) \n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea573657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the dataset in JSON representation\n",
    "ds_url_json = ds_url.replace('format=xml', 'format=json')\n",
    "print(\"retrieving \" + ds_url_json)\n",
    "response = requests.get(ds_url_json)\n",
    "json_dataset = response.text\n",
    "print(json_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921e9cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the dataset in JSON representation and extended view\n",
    "ds_url_json_ext = ds_url_json + '&view=extended'\n",
    "print(\"retrieving \" + ds_url_json_ext)\n",
    "response = requests.get(ds_url_json_ext)\n",
    "json_dataset_ext = response.text\n",
    "print(json_dataset_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aba235e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract exchanges as separate data frame\n",
    "process = response.json()\n",
    "dfex = pd.DataFrame.from_dict(pd.json_normalize(process['exchanges'], record_path='exchange'), orient='columns')\n",
    "#dfex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c93a9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up\n",
    "dfex.drop(['referenceToFlowDataSet.type', 'referenceToFlowDataSet.uri'], axis=1, inplace=True)\n",
    "dfex.rename(columns = {'referenceToFlowDataSet.shortDescription':'flow name'}, inplace=True)\n",
    "dfex['flow name'] = dfex['flow name'].apply(lambda x: x[0])\n",
    "dfex['flow name'] = dfex['flow name'].apply(lambda x: x['value'])\n",
    "dfex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397227ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
